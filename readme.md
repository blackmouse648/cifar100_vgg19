# cifar100 with vgg19_Bn

***

## 第一次尝试使用代码全自动生成模型，解放c&v
## 对原来使用的FC全连接模型进行了一些升级，准确率也是由25%提升到了59%
## 学习笔记： batchnormal2d批归一化层的使用， 
### nn.batchnoraml2d(), 以下为其内部参数

1.num_features：一般输入参数为该隐藏层其中特征的数量

2.eps：分母中添加的一个值，目的是为了计算的稳定性，默认为：1e-5

3.momentum：一个用于运行过程中均值和方差的一个估计参数， 可能是一个稳定习俗吧，还暂时没有接触过

4.affine：会给定可以学习的系数矩阵gamma和beta， 也就是weights和bias，可以通过模型初始化的时候进行初始化

### 为什么要使用 batchnoraml():

与为什么要使用归一化操作差不多,主要就是加快收敛速度，可以换一个视角观察，对于这种重复性很大的网络，前一层的输入与开头网络的
输出又会有什么区别呢？因此，如果我们对于每一层的批次输出都进行归一化，那样想必肯定会有加速收敛的效果